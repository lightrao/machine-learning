{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Covariance\n",
    "\n",
    "Covariance measures the extent of how two random variables vary from their means in tandem.\n",
    "\n",
    "- Formula of covariance is: $$\\frac{1}{n-1}\\sum_{i=1}^n (x_i-\\bar{x})(y_i-\\bar{y})$$\n",
    "Where:\n",
    "    - x, y are high-dimensional vectors\n",
    "    - $n$ = number of pairs in x and y\n",
    "    - $\\Sigma$ means sum up\n",
    "    - $x_i$ and $y_i$ are each pair of x,y values\n",
    "    - $\\bar{x}$ and $\\bar{y}$ are the mean of x and mean of y\n",
    "\n",
    "Covariance can take any value between -∞ and +∞, where a positive value indicates a direct relationship, a negative value indicates an inverse relationship, and a value near zero indicates no relationship. However, covariance doesn't provide information about the strength of the relationship, nor the slope of the relationship line, which is why correlation is often preferred when looking at the relationship between two variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation coefficient\n",
    "\n",
    "A correlation coefficient is a numerical measure of the strength and direction of a relationship between the relative movements of two random variables, say X and Y. Just divide the covariance by the standard deviations of both variables, and that normalizes things.\n",
    "\n",
    "- The formula of correlation coefficient is: $${\\displaystyle r_{xy}\\quad {\\overset {\\underset {\\mathrm {def} }{}}{=}}\\quad {\\frac {\\sum \\limits _{i=1}^{n}(x_{i}-{\\bar {x}})(y_{i}-{\\bar {y}})}{(n-1)s_{x}s_{y}}}={\\frac {\\sum \\limits _{i=1}^{n}(x_{i}-{\\bar {x}})(y_{i}-{\\bar {y}})}{\\sqrt {\\sum \\limits _{i=1}^{n}(x_{i}-{\\bar {x}})^{2}\\sum \\limits _{i=1}^{n}(y_{i}-{\\bar {y}})^{2}}}},}$$\n",
    "where:\n",
    "\n",
    "    - ${\\displaystyle r_{xy}}$ is the correlation coefficient of x and y. \n",
    "\n",
    "    - ${\\displaystyle \\sum \\limits _{i=1}^{n}(x_{i}-{\\bar {x}})(y_{i}-{\\bar {y}})}$ is the sum of the product of deviations of x and y from their respective means. This is essentially capturing the joint variability of x and y.\n",
    "\n",
    "    - ${\\displaystyle (n-1)s_{x}s_{y}}$ is the product of the sample standard deviations of x and y, multiplied by (n-1), where n is the sample size. The standard deviation is a measure of the amount of variation or dispersion of a set of values.\n",
    "\n",
    "    - ${\\displaystyle {\\sqrt {\\sum \\limits _{i=1}^{n}(x_{i}-{\\bar {x}})^{2}\\sum \\limits _{i=1}^{n}(y_{i}-{\\bar {y}})^{2}}}}$ is the square root of the product of the sum of squares of deviations of x and y from their respective means. This is basically normalizing the joint variability by the individual variabilities of x and y.\n",
    "\n",
    "The correlation coefficient r ranges from -1 to 1. A value of 1 implies a perfect positive correlation, i.e., for every increase in variable x, there is a proportional increase in y. A value of -1 implies a perfect negative correlation, i.e., for every increase in variable x, there is a proportional decrease in y. A value of 0 implies that there is no linear relationship between the variables.\n",
    "\n",
    "It's important to note that correlation does not imply causation. Just because two variables are correlated does not mean that changes in one variable cause changes in the other. Only a controlled, randomized experiment can give you insights on causation. Use correlation to decide what experiments to conduct!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lightTf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
